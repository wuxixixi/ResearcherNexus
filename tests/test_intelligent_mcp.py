#!/usr/bin/env python3
"""
æµ‹è¯•æ™ºèƒ½MCPå·¥å…·é€‰æ‹©å’Œä¸»åŠ¨è°ƒç”¨åŠŸèƒ½
"""

import asyncio
import json
import logging
from src.graph.builder import build_graph_with_memory

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_intelligent_mcp_selection():
    """æµ‹è¯•æ™ºèƒ½MCPå·¥å…·é€‰æ‹©åŠŸèƒ½"""
    
    # æ„å»ºå·¥ä½œæµå›¾
    graph = build_graph_with_memory()
    
    # é…ç½® - ä½¿ç”¨æ™ºèƒ½å·¥å…·é€‰æ‹©
    config = {
        "configurable": {
            "thread_id": "test_intelligent_mcp_001",
            "max_plan_iterations": 1,
            "max_step_num": 3,
            "max_search_results": 3,
            "mcp_settings": {
                "servers": {
                    # å†…å­˜å·¥å…· - åº”è¯¥è¢«è‡ªåŠ¨é€‰æ‹©ç”¨äºå­˜å‚¨ç ”ç©¶å‘ç°
                    "memory-server": {
                        "transport": "stdio",
                        "command": "npx",
                        "args": ["@modelcontextprotocol/server-memory"],
                        "enabled_tools": ["create_memory", "search_memory"]
                        # æ³¨æ„ï¼šæ²¡æœ‰æ˜¾å¼æŒ‡å®šadd_to_agentsï¼Œæµ‹è¯•æ™ºèƒ½é€‰æ‹©
                    },
                    
                    # æ–‡ä»¶ç³»ç»Ÿå·¥å…· - åº”è¯¥è¢«è‡ªåŠ¨é€‰æ‹©ç”¨äºæ–‡æ¡£å¤„ç†
                    "filesystem": {
                        "transport": "stdio",
                        "command": "npx",
                        "args": ["@modelcontextprotocol/server-filesystem", "D:\\"],
                        "enabled_tools": ["read_file", "list_directory"]
                        # æ³¨æ„ï¼šæ²¡æœ‰æ˜¾å¼æŒ‡å®šadd_to_agentsï¼Œæµ‹è¯•æ™ºèƒ½é€‰æ‹©
                    },
                    
                    # é¡ºåºæ€è€ƒå·¥å…· - åº”è¯¥è¢«è‡ªåŠ¨é€‰æ‹©ç”¨äºåˆ†æä»»åŠ¡
                    "sequential-thinking": {
                        "transport": "stdio",
                        "command": "npx",
                        "args": ["@modelcontextprotocol/server-sequential-thinking"],
                        "enabled_tools": ["think_step_by_step"]
                        # æ³¨æ„ï¼šæ²¡æœ‰æ˜¾å¼æŒ‡å®šadd_to_agentsï¼Œæµ‹è¯•æ™ºèƒ½é€‰æ‹©
                    }
                }
            }
        },
        "recursion_limit": 100
    }
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„ç ”ç©¶ä»»åŠ¡
    test_cases = [
        {
            "name": "æ•°æ®åˆ†æç ”ç©¶",
            "query": "åˆ†æ2024å¹´å…¨çƒAIå¸‚åœºçš„æ•°æ®è¶‹åŠ¿ï¼ŒåŒ…æ‹¬å¸‚åœºè§„æ¨¡ã€å¢é•¿ç‡å’Œä¸»è¦å‚ä¸è€…çš„ç»Ÿè®¡ä¿¡æ¯",
            "expected_tools": ["memory", "analysis", "search"]
        },
        {
            "name": "æ–‡æ¡£å¤„ç†ç ”ç©¶", 
            "query": "è¯»å–æœ¬åœ°æ–‡æ¡£å¹¶åˆ†æå…¶ä¸­çš„æŠ€æœ¯æ–‡æ¡£å†…å®¹ï¼Œæ•´ç†æˆç»“æ„åŒ–æŠ¥å‘Š",
            "expected_tools": ["filesystem", "memory", "analysis"]
        },
        {
            "name": "æ·±åº¦æœç´¢ç ”ç©¶",
            "query": "æ·±å…¥ç ”ç©¶é‡å­è®¡ç®—çš„æœ€æ–°å‘å±•ï¼Œæ¢ç´¢å­¦æœ¯è®ºæ–‡å’ŒæŠ€æœ¯æŠ¥å‘Š",
            "expected_tools": ["search", "memory", "citation"]
        },
        {
            "name": "ç»¼åˆåˆ†æç ”ç©¶",
            "query": "å­˜å‚¨å’Œåˆ†æå¤šä¸ªæ•°æ®æºçš„ä¿¡æ¯ï¼Œå»ºç«‹çŸ¥è¯†å›¾è°±å¹¶ç”Ÿæˆæ´å¯ŸæŠ¥å‘Š",
            "expected_tools": ["memory", "analysis", "search", "database"]
        }
    ]
    
    for i, test_case in enumerate(test_cases):
        print(f"\n{'='*60}")
        print(f"ğŸ§ª æµ‹è¯•æ¡ˆä¾‹ {i+1}: {test_case['name']}")
        print(f"ğŸ“‹ æŸ¥è¯¢: {test_case['query']}")
        print(f"ğŸ¯ é¢„æœŸå·¥å…·ç±»å‹: {', '.join(test_case['expected_tools'])}")
        print(f"{'='*60}")
        
        # æ›´æ–°é…ç½®ä¸­çš„thread_id
        config["configurable"]["thread_id"] = f"test_intelligent_mcp_{i+1:03d}"
        
        # åˆå§‹çŠ¶æ€
        initial_state = {
            "messages": [{"role": "user", "content": test_case["query"]}],
            "auto_accepted_plan": True,
            "enable_background_investigation": False,
            "locale": "zh-CN"
        }
        
        try:
            print("ğŸš€ å¼€å§‹æ‰§è¡Œç ”ç©¶å·¥ä½œæµ...")
            
            step_count = 0
            async for state in graph.astream(initial_state, config=config):
                step_count += 1
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ä¿¡æ¯
                if "messages" in state:
                    for message in state["messages"]:
                        if hasattr(message, "content") and "tool" in str(message.content).lower():
                            print(f"ğŸ”§ æ£€æµ‹åˆ°å·¥å…·ä½¿ç”¨: {message.content[:100]}...")
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if "final_report" in state:
                    print("âœ… ç ”ç©¶å®Œæˆ!")
                    print(f"ğŸ“Š æ€»æ­¥éª¤æ•°: {step_count}")
                    break
                    
                # é˜²æ­¢æ— é™å¾ªç¯
                if step_count > 20:
                    print("âš ï¸ è¾¾åˆ°æœ€å¤§æ­¥éª¤é™åˆ¶ï¼Œåœæ­¢æ‰§è¡Œ")
                    break
                    
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        print(f"âœ… æµ‹è¯•æ¡ˆä¾‹ {i+1} å®Œæˆ\n")


async def test_tool_recommendation_algorithm():
    """æµ‹è¯•å·¥å…·æ¨èç®—æ³•"""
    
    print("\nğŸ§  æµ‹è¯•å·¥å…·æ¨èç®—æ³•")
    print("="*50)
    
    # å¯¼å…¥å·¥å…·æ¨èå‡½æ•°
    from src.graph.nodes import _get_intelligent_tool_recommendations
    
    test_scenarios = [
        {
            "title": "æ•°æ®åˆ†ææŠ¥å‘Š",
            "description": "åˆ†æé”€å”®æ•°æ®ï¼Œè®¡ç®—ç»Ÿè®¡æŒ‡æ ‡ï¼Œç”Ÿæˆè¶‹åŠ¿å›¾è¡¨",
            "agent": "researcher",
            "expected": ["analysis", "memory"]
        },
        {
            "title": "æ–‡ä»¶å¤„ç†ä»»åŠ¡",
            "description": "è¯»å–CSVæ–‡ä»¶ï¼Œå¤„ç†æ•°æ®å¹¶å†™å…¥æ–°çš„JSONæ–‡ä»¶",
            "agent": "coder", 
            "expected": ["filesystem", "analysis"]
        },
        {
            "title": "å­¦æœ¯ç ”ç©¶",
            "description": "æœç´¢æœ€æ–°çš„æœºå™¨å­¦ä¹ è®ºæ–‡ï¼Œæ•´ç†å‚è€ƒæ–‡çŒ®",
            "agent": "researcher",
            "expected": ["search", "citation", "memory"]
        },
        {
            "title": "æ•°æ®åº“æŸ¥è¯¢",
            "description": "æŸ¥è¯¢ç”¨æˆ·æ•°æ®åº“ï¼Œåˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼",
            "agent": "coder",
            "expected": ["database", "analysis"]
        }
    ]
    
    for i, scenario in enumerate(test_scenarios):
        print(f"\nğŸ“‹ åœºæ™¯ {i+1}: {scenario['title']}")
        print(f"ğŸ“ æè¿°: {scenario['description']}")
        print(f"ğŸ¤– ä»£ç†: {scenario['agent']}")
        
        recommendations = _get_intelligent_tool_recommendations(
            scenario["title"],
            scenario["description"], 
            scenario["agent"]
        )
        
        print(f"ğŸ¯ æ¨èç»“æœ: {json.dumps(recommendations, indent=2, ensure_ascii=False)}")
        print(f"âœ… é¢„æœŸç±»å‹: {', '.join(scenario['expected'])}")
        
        # æ£€æŸ¥æ¨èæ˜¯å¦åŒ…å«é¢„æœŸçš„å·¥å…·ç±»å‹
        recommended_categories = set(recommendations.keys())
        expected_categories = set(scenario["expected"])
        
        if expected_categories.issubset(recommended_categories):
            print("âœ… æ¨èå‡†ç¡®!")
        else:
            missing = expected_categories - recommended_categories
            print(f"âš ï¸ ç¼ºå°‘æ¨è: {', '.join(missing)}")


async def test_mcp_server_connectivity():
    """æµ‹è¯•MCPæœåŠ¡å™¨è¿æ¥æ€§"""
    
    print("\nğŸ”Œ æµ‹è¯•MCPæœåŠ¡å™¨è¿æ¥æ€§")
    print("="*50)
    
    # æµ‹è¯•å¸¸è§çš„MCPæœåŠ¡å™¨
    test_servers = [
        {
            "name": "Memory Server",
            "config": {
                "transport": "stdio",
                "command": "npx",
                "args": ["@modelcontextprotocol/server-memory"]
            }
        },
        {
            "name": "Sequential Thinking",
            "config": {
                "transport": "stdio",
                "command": "npx",
                "args": ["@modelcontextprotocol/server-sequential-thinking"]
            }
        },
        {
            "name": "Filesystem Server",
            "config": {
                "transport": "stdio",
                "command": "npx",
                "args": ["@modelcontextprotocol/server-filesystem", "D:\\"]
            }
        }
    ]
    
    for server in test_servers:
        print(f"\nğŸ§ª æµ‹è¯•æœåŠ¡å™¨: {server['name']}")
        
        try:
            # ä½¿ç”¨APIæµ‹è¯•æœåŠ¡å™¨
            import requests
            
            response = requests.post(
                "http://localhost:8000/api/mcp/server/metadata",
                json=server["config"],
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                tools = result.get('tools', [])
                print(f"âœ… è¿æ¥æˆåŠŸ! è·å–åˆ° {len(tools)} ä¸ªå·¥å…·")
                
                if tools:
                    for tool in tools[:3]:  # æ˜¾ç¤ºå‰3ä¸ªå·¥å…·
                        print(f"   - {tool.get('name', 'Unknown')}: {tool.get('description', 'No description')[:50]}...")
                else:
                    print("âš ï¸ æœåŠ¡å™¨è¿”å›ç©ºå·¥å…·åˆ—è¡¨")
            else:
                print(f"âŒ è¿æ¥å¤±è´¥: HTTP {response.status_code}")
                print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
                
        except requests.exceptions.Timeout:
            print("âŒ è¿æ¥è¶…æ—¶")
        except requests.exceptions.ConnectionError:
            print("âŒ æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡å™¨")
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")


async def diagnose_current_issue():
    """è¯Šæ–­å½“å‰çš„MCPé—®é¢˜"""
    
    print("\nğŸ” è¯Šæ–­å½“å‰MCPé—®é¢˜")
    print("="*50)
    
    # æµ‹è¯•æ‚¨é‡åˆ°çš„å…·ä½“é…ç½®
    problematic_config = {
        "transport": "stdio",
        "command": "cmd",
        "args": ["/c", "npx", "-y", "@smithery/cli@latest", "run", "@ameeralns/DeepResearchMCP", "--key", "741ccf4e-a807-4366-a4bf-cc8f3a9f277f"]
    }
    
    print("ğŸ§ª æµ‹è¯•é—®é¢˜é…ç½®:")
    print(f"   å‘½ä»¤: {problematic_config['command']}")
    print(f"   å‚æ•°: {' '.join(problematic_config['args'])}")
    
    try:
        import requests
        
        print("\nğŸ“¡ å‘é€æµ‹è¯•è¯·æ±‚...")
        response = requests.post(
            "http://localhost:8000/api/mcp/server/metadata",
            json=problematic_config,
            timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´
        )
        
        if response.status_code == 200:
            result = response.json()
            tools = result.get('tools', [])
            print(f"âœ… è¯·æ±‚æˆåŠŸ! è·å–åˆ° {len(tools)} ä¸ªå·¥å…·")
            
            if tools:
                print("ğŸ”§ å¯ç”¨å·¥å…·:")
                for tool in tools:
                    print(f"   - {tool.get('name', 'Unknown')}: {tool.get('description', 'No description')[:50]}...")
            else:
                print("âš ï¸ æœåŠ¡å™¨è¿”å›ç©ºå·¥å…·åˆ—è¡¨")
                print("ğŸ’¡ å¯èƒ½çš„åŸå› :")
                print("   1. SmitheryæœåŠ¡å™¨å¯åŠ¨å¤±è´¥")
                print("   2. APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
                print("   3. ç½‘ç»œè¿æ¥é—®é¢˜")
                print("   4. Windowsç¯å¢ƒå…¼å®¹æ€§é—®é¢˜")
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
            
    except requests.exceptions.Timeout:
        print("âŒ è¯·æ±‚è¶…æ—¶ (60ç§’)")
        print("ğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   2. éªŒè¯SmitheryæœåŠ¡æ˜¯å¦å¯ç”¨")
        print("   3. å°è¯•ä½¿ç”¨æ›´ç®€å•çš„MCPæœåŠ¡å™¨")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        
    # æä¾›æ›¿ä»£æ–¹æ¡ˆ
    print("\nğŸ’¡ æ¨èçš„æ›¿ä»£é…ç½®:")
    
    alternative_configs = [
        {
            "name": "Memory Server (æ¨è)",
            "config": {
                "transport": "stdio",
                "command": "npx",
                "args": ["@modelcontextprotocol/server-memory"]
            }
        },
        {
            "name": "Sequential Thinking",
            "config": {
                "transport": "stdio",
                "command": "npx",
                "args": ["@modelcontextprotocol/server-sequential-thinking"]
            }
        },
        {
            "name": "Filesystem Server",
            "config": {
                "transport": "stdio",
                "command": "npx",
                "args": ["@modelcontextprotocol/server-filesystem", "D:\\ResearcherNexus"]
            }
        }
    ]
    
    for alt in alternative_configs:
        print(f"\nğŸ”§ {alt['name']}:")
        print(f"   å‘½ä»¤: {alt['config']['command']}")
        print(f"   å‚æ•°: {' '.join(alt['config']['args'])}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    
    print("ğŸš€ å¼€å§‹MCPé—®é¢˜è¯Šæ–­å’Œæµ‹è¯•")
    print("="*60)
    
    # é¦–å…ˆè¯Šæ–­å½“å‰é—®é¢˜
    await diagnose_current_issue()
    
    # æµ‹è¯•æœåŠ¡å™¨è¿æ¥æ€§
    await test_mcp_server_connectivity()
    
    # æµ‹è¯•å·¥å…·æ¨èç®—æ³•
    await test_tool_recommendation_algorithm()
    
    # å¦‚æœåŸºç¡€æµ‹è¯•é€šè¿‡ï¼Œå†æµ‹è¯•å®Œæ•´æµç¨‹
    print("\nâ“ æ˜¯å¦ç»§ç»­æµ‹è¯•å®Œæ•´çš„æ™ºèƒ½å·¥å…·é€‰æ‹©æµç¨‹ï¼Ÿ")
    print("   (éœ€è¦ç¡®ä¿è‡³å°‘ä¸€ä¸ªMCPæœåŠ¡å™¨å¯ç”¨)")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ ç”¨æˆ·è¾“å…¥ï¼Œä½†ä¸ºäº†è‡ªåŠ¨åŒ–æµ‹è¯•ï¼Œæˆ‘ä»¬è·³è¿‡
    # await test_intelligent_mcp_selection()
    
    print("\nğŸ‰ è¯Šæ–­å®Œæˆ!")
    print("="*60)
    print("ğŸ“ é—®é¢˜æ€»ç»“:")
    print("1. SmitheryæœåŠ¡å™¨å¯èƒ½å­˜åœ¨è¿æ¥æˆ–å…¼å®¹æ€§é—®é¢˜")
    print("2. å»ºè®®ä½¿ç”¨æ›´ç¨³å®šçš„MCPæœåŠ¡å™¨ï¼ˆå¦‚Memory Serverï¼‰")
    print("3. æ™ºèƒ½å·¥å…·é€‰æ‹©åŠŸèƒ½å·²å®ç°ï¼Œç­‰å¾…MCPæœåŠ¡å™¨æ­£å¸¸å·¥ä½œ")
    print("4. å¯ä»¥é€šè¿‡æ—¥å¿—æŸ¥çœ‹è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    asyncio.run(main()) 